{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "in_channels = 2\n",
    "out_channels = 3\n",
    "height = 4\n",
    "width = 4\n",
    "rank = 2\n",
    "padding = 1\n",
    "stride = 1\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ori_calcul(input, C):\n",
    "    padded_I = nn.functional.pad(input, pad=[padding]*4)\n",
    "    padded_I = padded_I.permute(0, 2, 3, 1)\n",
    "    padded_h = padded_I.shape[1]\n",
    "    padded_w = padded_I.shape[2]\n",
    "    padded_I_col = padded_I.reshape(batch_size * padded_h * padded_w, in_channels)\n",
    "    weight_col = C.reshape(in_channels, out_channels * rank)\n",
    "    output = torch.matmul(padded_I_col, weight_col).reshape(batch_size, padded_h, padded_w, out_channels, rank)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_calcul(input, C):\n",
    "    output = torch.zeros(batch_size, height+2*padding, width+2*padding, out_channels, rank)\n",
    "    for i in range(out_channels):\n",
    "        conv = nn.Conv2d(in_channels, rank, 1, padding=padding, bias=False)\n",
    "        conv.weight.data = C[:, i, :].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv(input)\n",
    "        output[:, :, :, i] = out.permute(0, 2, 3, 1)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([[[[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]]]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(batch_size, in_channels, height, width)\n",
    "C = torch.rand(in_channels, out_channels, rank)\n",
    "\n",
    "ori_out = ori_calcul(input, C)\n",
    "my_out = my_calcul(input, C).detach().clone()\n",
    "print(torch.all(torch.lt(torch.abs(torch.add(ori_out, -my_out)), 1e-12)))\n",
    "print(torch.eq(ori_out, my_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 6, 3, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ori_body(input, B):\n",
    "    w = input.size(2) - 2*padding\n",
    "    Oc = input.permute(0, 1, 3, 4, 2)\n",
    "    # Add a new axis to B for broadcasting, B's shape becomes (1, 1, Cout, r, 1, d)\n",
    "    B_expanded = B[None, None, :, :, None, :]\n",
    "    # Assuming 'Oc' is a 5-dimensional and 'w' and 'd' are the window width and depth, respectively\n",
    "    window_indices = torch.arange(start=0, end=w, step=stride)[:, None] + torch.arange(kernel_size)\n",
    "    Oc_expanded = Oc[:, :, :, :, window_indices]\n",
    "\n",
    "    # Perform the element-wise multiplication and sum over the last axis (d)\n",
    "    output = torch.sum(Oc_expanded * B_expanded, dim=-1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.rand(out_channels, rank, kernel_size)\n",
    "ori_out_body = ori_body(ori_out, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0584, 0.8072, 0.5685, 0.8712],\n",
      "           [0.1074, 0.8548, 0.2802, 0.4322]],\n",
      "\n",
      "          [[0.3180, 0.5677, 0.5819, 0.2089],\n",
      "           [0.1709, 0.7285, 0.3866, 0.3973]],\n",
      "\n",
      "          [[0.6018, 0.6952, 0.7753, 0.8649],\n",
      "           [0.6341, 1.5196, 1.2646, 0.8859]]],\n",
      "\n",
      "\n",
      "         [[[0.0352, 0.5157, 0.3331, 0.6375],\n",
      "           [0.3577, 0.4239, 0.3442, 0.1625]],\n",
      "\n",
      "          [[0.1349, 0.4280, 0.2980, 0.1556],\n",
      "           [0.3239, 0.4277, 0.3351, 0.1689]],\n",
      "\n",
      "          [[0.3291, 0.2908, 0.5857, 0.5190],\n",
      "           [0.5138, 1.0133, 0.7888, 0.5281]]],\n",
      "\n",
      "\n",
      "         [[[0.1133, 0.8163, 1.1251, 0.7989],\n",
      "           [0.6182, 0.2720, 0.7370, 0.0869]],\n",
      "\n",
      "          [[0.5863, 0.6727, 0.3470, 0.1827],\n",
      "           [0.5590, 0.3944, 0.6298, 0.1526]],\n",
      "\n",
      "          [[0.7073, 1.0874, 1.0169, 0.3443],\n",
      "           [1.2768, 1.4639, 1.3034, 0.5728]]],\n",
      "\n",
      "\n",
      "         [[[0.0612, 0.6098, 0.5623, 0.2385],\n",
      "           [0.5533, 0.3611, 0.5582, 0.1011]],\n",
      "\n",
      "          [[0.2617, 0.2535, 0.1572, 0.0512],\n",
      "           [0.4893, 0.3969, 0.4659, 0.1155]],\n",
      "\n",
      "          [[0.4530, 0.4432, 0.2682, 0.1204],\n",
      "           [0.8235, 0.8593, 0.7301, 0.2376]]],\n",
      "\n",
      "\n",
      "         [[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]]]]])\n",
      "torch.Size([1, 6, 3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(ori_out_body)\n",
    "print(ori_out_body.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_body(input, C, B):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "    for i in range(out_channels):\n",
    "        conv_head = nn.Conv2d(in_channels, rank, 1, padding=0, bias=False)\n",
    "        conv_head.weight.data = C[:, i, :].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv_head(input)\n",
    "        conv_body = nn.Conv2d(rank, 1, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "        conv_body.weight.data = B[i].unsqueeze(0).unsqueeze(2)\n",
    "        out = conv_body(out)\n",
    "\n",
    "        output[:, i] = out\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_out_body = my_body(input, C, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1658, 1.6620, 0.8488, 1.3033],\n",
      "          [0.3929, 0.9397, 0.6773, 0.8000],\n",
      "          [0.7315, 1.0883, 1.8622, 0.8857],\n",
      "          [0.6145, 0.9710, 1.1205, 0.3396]],\n",
      "\n",
      "         [[0.4889, 1.2962, 0.9685, 0.6061],\n",
      "          [0.4588, 0.8556, 0.6331, 0.3245],\n",
      "          [1.1453, 1.0671, 0.9767, 0.3353],\n",
      "          [0.7510, 0.6505, 0.6231, 0.1667]],\n",
      "\n",
      "         [[1.2358, 2.2148, 2.0399, 1.7508],\n",
      "          [0.8429, 1.3041, 1.3745, 1.0471],\n",
      "          [1.9841, 2.5514, 2.3203, 0.9172],\n",
      "          [1.2765, 1.3025, 0.9983, 0.3580]]]], grad_fn=<CopySlices>)\n",
      "torch.Size([1, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(my_out_body)\n",
    "print(my_out_body.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ori_tail(input, A):\n",
    "    h = input.size(1) - 2*padding\n",
    "    Ob = input.permute(0, 4, 2, 3, 1)\n",
    "    # Add a new axis to B for broadcasting, A's shape becomes (1, 1, Cout, r, 1, d)\n",
    "    A_expanded = A[None, None, :, :, None, :]\n",
    "\n",
    "    # Assuming 'Ob' is a 5-dimensional and 'h' and 'd' are the window width and depth, respectively\n",
    "    window_indices = torch.arange(start=0, end=h, step=stride)[:, None] + torch.arange(kernel_size)\n",
    "    Ob_expanded = Ob[:, :, :, :, window_indices]\n",
    "\n",
    "    # Perform the element-wise multiplication and sum over the last axis (d)\n",
    "    Oa = torch.sum(Ob_expanded * A_expanded, axis=-1)\n",
    "\n",
    "    Oa = Oa.permute(0, 4, 1, 2, 3)\n",
    "\n",
    "    # print(Oa)\n",
    "\n",
    "    # Step 4: Compute O\n",
    "    output = torch.sum(Oa, dim=-1)\n",
    "\n",
    "    # print(output)\n",
    "\n",
    "    output = output.permute(0, 3, 1, 2)\n",
    "    # print(output)\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(out_channels, rank, kernel_size)\n",
    "ori_out_tail = ori_tail(ori_out_body, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1501, 1.0284, 0.6259, 0.9927],\n",
       "          [0.4202, 1.9828, 1.7689, 1.6817],\n",
       "          [0.6004, 1.4801, 1.5663, 0.9666],\n",
       "          [0.6038, 0.9097, 1.3912, 0.5852]],\n",
       "\n",
       "         [[0.5948, 0.9537, 0.8535, 0.3682],\n",
       "          [0.8837, 1.5442, 1.3040, 0.6932],\n",
       "          [1.3286, 1.4310, 1.1224, 0.4507],\n",
       "          [0.8326, 0.6714, 0.7885, 0.2108]],\n",
       "\n",
       "         [[0.9234, 1.5056, 1.3871, 1.1832],\n",
       "          [2.3927, 3.5863, 3.4348, 2.4604],\n",
       "          [2.1241, 2.8999, 2.7304, 1.4651],\n",
       "          [2.3006, 2.7939, 2.4352, 0.9714]]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_out_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tail(input, C, B, A):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "\n",
    "    for i in range(out_channels):\n",
    "\n",
    "        conv_head = nn.Conv2d(in_channels, rank, 1, padding=0, bias=False)\n",
    "        conv_head.weight.data = C[:, i, :].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv_head(input)\n",
    "        conv_body = nn.Conv2d(rank, 1, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "        conv_body.weight.data = B[i].unsqueeze(0).unsqueeze(2)\n",
    "        out = conv_body(out)\n",
    "\n",
    "        conv_tail = nn.Conv2d(1, rank, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "        conv_tail.weight.data = A[i].unsqueeze(1).unsqueeze(-1)\n",
    "        out = conv_tail(out)\n",
    "\n",
    "        # print(out.shape)\n",
    "        # print(out)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        # print(out.shape)\n",
    "        # print(out)\n",
    "\n",
    "\n",
    "        output[:, i] = out\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5102, 2.0036, 1.2280, 1.6367],\n",
       "          [1.1911, 3.6057, 3.3186, 2.9001],\n",
       "          [1.5382, 2.7524, 3.0874, 1.8128],\n",
       "          [1.2146, 1.8421, 2.8170, 1.2202]],\n",
       "\n",
       "         [[0.9048, 2.0377, 1.5164, 0.8772],\n",
       "          [2.0718, 3.1927, 2.5595, 1.2602],\n",
       "          [2.2717, 2.5114, 2.1708, 0.8091],\n",
       "          [1.8730, 1.7001, 1.5814, 0.4998]],\n",
       "\n",
       "         [[1.7565, 2.9829, 2.8860, 2.3710],\n",
       "          [4.5414, 7.1550, 6.7183, 4.7912],\n",
       "          [4.2707, 5.6158, 5.2966, 2.9681],\n",
       "          [4.6774, 5.7178, 5.0369, 1.9589]]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tail(input, C, B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_other(input, C, B, A):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "    for i in range(out_channels):\n",
    "\n",
    "        conv_head = nn.Conv2d(in_channels, rank, 1, padding=0, bias=False)\n",
    "        conv_head.weight.data = C[:, i, :].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv_head(input)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        output[:, i] = out\n",
    "\n",
    "    conv_body = nn.Conv2d(out_channels, rank, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "    conv_body.weight.data = B.permute(1, 0, 2).unsqueeze(2)\n",
    "    output = conv_body(output)\n",
    "\n",
    "    conv_tail = nn.Conv2d(rank, out_channels, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "    conv_tail.weight.data = A.unsqueeze(-1)\n",
    "    output = conv_tail(output)\n",
    "\n",
    "    # print(out.shape)\n",
    "    # print(out)\n",
    "    # out = torch.sum(out, dim=1)\n",
    "    # print(out.shape)\n",
    "    # print(out)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.8290,  5.9203,  5.3343,  4.5124],\n",
       "          [ 6.8386, 12.7874, 11.5765,  7.5944],\n",
       "          [ 6.5085,  9.9331,  8.8002,  4.6937],\n",
       "          [ 6.1629,  7.7181,  7.2002,  3.0241]],\n",
       "\n",
       "         [[ 3.6090,  7.6436,  6.3064,  5.5358],\n",
       "          [ 8.6532, 14.1680, 12.3749,  7.6686],\n",
       "          [ 7.6412, 11.4409, 10.2043,  4.9115],\n",
       "          [ 6.9913,  8.3687,  7.4327,  3.1170]],\n",
       "\n",
       "         [[ 3.2049,  6.9593,  5.7525,  4.9095],\n",
       "          [ 8.9991, 16.1579, 14.0614, 10.0175],\n",
       "          [ 8.2643, 12.7301, 11.4814,  6.3622],\n",
       "          [ 9.3103, 11.8172, 11.0133,  4.6841]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_other(input, C, B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_another(input, C, B, A):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "\n",
    "    for i in range(out_channels):\n",
    "        sum = torch.zeros(batch_size, 1, height, width)\n",
    "        for j in range(rank):\n",
    "\n",
    "            conv_head = nn.Conv2d(in_channels, 1, 1, padding=0, bias=False)\n",
    "            conv_head.weight.data = C[:, i, j].unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "            out = conv_head(input)\n",
    "\n",
    "            conv_body = nn.Conv2d(1, 1, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "            conv_body.weight.data = B[i, j].unsqueeze(0).unsqueeze(0).unsqueeze(0)\n",
    "            out = conv_body(out)\n",
    "\n",
    "            conv_tail = nn.Conv2d(1, 1, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "            conv_tail.weight.data = A[i, j].unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "            out = conv_tail(out)                      \n",
    "\n",
    "            sum += out\n",
    "\n",
    "        output[:, i] = sum\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1501, 1.0284, 0.6259, 0.9927],\n",
       "          [0.4202, 1.9828, 1.7689, 1.6817],\n",
       "          [0.6004, 1.4801, 1.5663, 0.9666],\n",
       "          [0.6038, 0.9097, 1.3912, 0.5852]],\n",
       "\n",
       "         [[0.5948, 0.9537, 0.8535, 0.3682],\n",
       "          [0.8837, 1.5442, 1.3040, 0.6932],\n",
       "          [1.3286, 1.4310, 1.1224, 0.4507],\n",
       "          [0.8326, 0.6714, 0.7885, 0.2108]],\n",
       "\n",
       "         [[0.9234, 1.5056, 1.3871, 1.1832],\n",
       "          [2.3927, 3.5863, 3.4348, 2.4604],\n",
       "          [2.1241, 2.8999, 2.7304, 1.4651],\n",
       "          [2.3006, 2.7939, 2.4352, 0.9714]]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_another(input, C, B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func1(input, C, B, A):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "\n",
    "    for j in range(rank):\n",
    "\n",
    "        conv_head = nn.Conv2d(in_channels, out_channels, 1, padding=0, bias=False)\n",
    "        conv_head.weight.data = C[:, :, j].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv_head(input)\n",
    "\n",
    "        conv_body = nn.Conv2d(out_channels, 1, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "        conv_body.weight.data = B[:, j].unsqueeze(0).unsqueeze(2)\n",
    "        out = conv_body(out)\n",
    "\n",
    "        conv_tail = nn.Conv2d(1, out_channels, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "        conv_tail.weight.data = A[:, j].unsqueeze(1).unsqueeze(-1)\n",
    "        out = conv_tail(out)\n",
    "\n",
    "        output += out\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8323, 1.7989, 1.5240, 1.1652],\n",
       "          [3.4157, 6.0044, 6.0656, 4.2418],\n",
       "          [2.5548, 4.1356, 4.1657, 2.4511],\n",
       "          [2.9785, 4.1634, 4.1622, 1.8136]],\n",
       "\n",
       "         [[1.9587, 4.0324, 3.6233, 3.1005],\n",
       "          [4.9612, 8.3164, 7.8639, 4.8326],\n",
       "          [3.9593, 5.6802, 5.2868, 2.5720],\n",
       "          [2.3324, 3.1258, 3.3784, 1.3571]],\n",
       "\n",
       "         [[2.6241, 5.2695, 4.7364, 4.0373],\n",
       "          [4.0072, 7.2106, 7.1663, 5.1479],\n",
       "          [4.9980, 7.5350, 7.2089, 3.5260],\n",
       "          [3.7216, 4.7828, 4.5968, 1.8483]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func1(input, C, A, B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
