{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "in_channels = 2\n",
    "out_channels = 3\n",
    "height = 4\n",
    "width = 4\n",
    "rank = 2\n",
    "padding = 1\n",
    "stride = 1\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ori_calcul(input, C):\n",
    "    padded_I = nn.functional.pad(input, pad=[padding]*4)\n",
    "    padded_I = padded_I.permute(0, 2, 3, 1)\n",
    "    padded_h = padded_I.shape[1]\n",
    "    padded_w = padded_I.shape[2]\n",
    "    padded_I_col = padded_I.reshape(batch_size * padded_h * padded_w, in_channels)\n",
    "    weight_col = C.reshape(in_channels, out_channels * rank)\n",
    "    output = torch.matmul(padded_I_col, weight_col).reshape(batch_size, padded_h, padded_w, out_channels, rank)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_calcul(input, C):\n",
    "    output = torch.zeros(batch_size, height+2*padding, width+2*padding, out_channels, rank)\n",
    "    for i in range(out_channels):\n",
    "        conv = nn.Conv2d(in_channels, rank, 1, padding=padding, bias=False)\n",
    "        conv.weight.data = C[:, i, :].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv(input)\n",
    "        output[:, :, :, i] = out.permute(0, 2, 3, 1)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([[[[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]],\n",
      "\n",
      "\n",
      "         [[[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]],\n",
      "\n",
      "          [[True, True],\n",
      "           [True, True],\n",
      "           [True, True]]]]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(batch_size, in_channels, height, width)\n",
    "C = torch.rand(in_channels, out_channels, rank)\n",
    "\n",
    "ori_out = ori_calcul(input, C)\n",
    "my_out = my_calcul(input, C).detach().clone()\n",
    "print(torch.all(torch.lt(torch.abs(torch.add(ori_out, -my_out)), 1e-12)))\n",
    "print(torch.eq(ori_out, my_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 6, 3, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_head(input, C):\n",
    "    output = torch.zeros(batch_size, height+2*padding, width+2*padding, out_channels, rank)\n",
    "    conv = nn.Conv2d(in_channels, out_channels*rank, 1, padding=padding, bias=False)\n",
    "    conv.weight.data = C.reshape(in_channels, out_channels*rank).permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "    out = conv(input)\n",
    "    out = out.reshape(batch_size, out_channels, rank, height+2*padding, width+2*padding)\n",
    "    output = out.permute(0, 3, 4, 1, 2)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "         [[[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0508, 0.7597],\n",
       "           [0.2611, 0.4634],\n",
       "           [0.2565, 0.0368]],\n",
       "\n",
       "          [[0.0619, 0.6816],\n",
       "           [0.3019, 0.4350],\n",
       "           [0.2953, 0.0411]],\n",
       "\n",
       "          [[0.0807, 0.9394],\n",
       "           [0.3970, 0.5941],\n",
       "           [0.3886, 0.0544]],\n",
       "\n",
       "          [[0.1108, 0.6109],\n",
       "           [0.4994, 0.4551],\n",
       "           [0.4851, 0.0640]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "         [[[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0012, 0.8735],\n",
       "           [0.0640, 0.4654],\n",
       "           [0.0673, 0.0143]],\n",
       "\n",
       "          [[0.0983, 0.8676],\n",
       "           [0.4648, 0.5767],\n",
       "           [0.4535, 0.0619]],\n",
       "\n",
       "          [[0.0876, 0.6640],\n",
       "           [0.4071, 0.4560],\n",
       "           [0.3966, 0.0535]],\n",
       "\n",
       "          [[0.0873, 0.2569],\n",
       "           [0.3782, 0.2394],\n",
       "           [0.3660, 0.0469]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "         [[[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0081, 0.5965],\n",
       "           [0.0735, 0.3263],\n",
       "           [0.0747, 0.0133]],\n",
       "\n",
       "          [[0.1219, 0.9646],\n",
       "           [0.5690, 0.6561],\n",
       "           [0.5545, 0.0750]],\n",
       "\n",
       "          [[0.1010, 0.2370],\n",
       "           [0.4336, 0.2450],\n",
       "           [0.4192, 0.0533]],\n",
       "\n",
       "          [[0.0902, 0.7446],\n",
       "           [0.4229, 0.5018],\n",
       "           [0.4123, 0.0560]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "         [[[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.1013, 0.2344],\n",
       "           [0.4347, 0.2440],\n",
       "           [0.4203, 0.0534]],\n",
       "\n",
       "          [[0.1296, 0.2839],\n",
       "           [0.5550, 0.3036],\n",
       "           [0.5365, 0.0681]],\n",
       "\n",
       "          [[0.0306, 0.4835],\n",
       "           [0.1591, 0.2929],\n",
       "           [0.1564, 0.0226]],\n",
       "\n",
       "          [[0.1019, 0.9909],\n",
       "           [0.4882, 0.6465],\n",
       "           [0.4768, 0.0656]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "         [[[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]],\n",
       "\n",
       "          [[0.0000, 0.0000],\n",
       "           [0.0000, 0.0000],\n",
       "           [0.0000, 0.0000]]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0508, 0.7597],\n",
      "           [0.2611, 0.4634],\n",
      "           [0.2565, 0.0368]],\n",
      "\n",
      "          [[0.0619, 0.6816],\n",
      "           [0.3019, 0.4350],\n",
      "           [0.2953, 0.0411]],\n",
      "\n",
      "          [[0.0807, 0.9394],\n",
      "           [0.3970, 0.5941],\n",
      "           [0.3886, 0.0544]],\n",
      "\n",
      "          [[0.1108, 0.6109],\n",
      "           [0.4994, 0.4551],\n",
      "           [0.4851, 0.0640]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0012, 0.8735],\n",
      "           [0.0640, 0.4654],\n",
      "           [0.0673, 0.0143]],\n",
      "\n",
      "          [[0.0983, 0.8676],\n",
      "           [0.4648, 0.5767],\n",
      "           [0.4535, 0.0619]],\n",
      "\n",
      "          [[0.0876, 0.6640],\n",
      "           [0.4071, 0.4560],\n",
      "           [0.3966, 0.0535]],\n",
      "\n",
      "          [[0.0873, 0.2569],\n",
      "           [0.3782, 0.2394],\n",
      "           [0.3660, 0.0469]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0081, 0.5965],\n",
      "           [0.0735, 0.3263],\n",
      "           [0.0747, 0.0133]],\n",
      "\n",
      "          [[0.1219, 0.9646],\n",
      "           [0.5690, 0.6561],\n",
      "           [0.5545, 0.0750]],\n",
      "\n",
      "          [[0.1010, 0.2370],\n",
      "           [0.4336, 0.2450],\n",
      "           [0.4192, 0.0533]],\n",
      "\n",
      "          [[0.0902, 0.7446],\n",
      "           [0.4229, 0.5018],\n",
      "           [0.4123, 0.0560]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.1013, 0.2344],\n",
      "           [0.4347, 0.2440],\n",
      "           [0.4203, 0.0534]],\n",
      "\n",
      "          [[0.1296, 0.2839],\n",
      "           [0.5550, 0.3036],\n",
      "           [0.5365, 0.0681]],\n",
      "\n",
      "          [[0.0306, 0.4835],\n",
      "           [0.1591, 0.2929],\n",
      "           [0.1564, 0.0226]],\n",
      "\n",
      "          [[0.1019, 0.9909],\n",
      "           [0.4882, 0.6465],\n",
      "           [0.4768, 0.0656]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000],\n",
      "           [0.0000, 0.0000],\n",
      "           [0.0000, 0.0000]]]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[[[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]]],\n",
      "\n",
      "\n",
      "         [[[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True, False],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]]],\n",
      "\n",
      "\n",
      "         [[[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True, False]],\n",
      "\n",
      "          [[False,  True],\n",
      "           [False, False],\n",
      "           [False,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [False, False],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]]],\n",
      "\n",
      "\n",
      "         [[[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[False,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [False,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [False, False]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]]],\n",
      "\n",
      "\n",
      "         [[[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [False,  True],\n",
      "           [False,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True, False],\n",
      "           [ True, False]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [False,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]]],\n",
      "\n",
      "\n",
      "         [[[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]],\n",
      "\n",
      "          [[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]]]]])\n"
     ]
    }
   ],
   "source": [
    "head_output = my_head(input, C)\n",
    "print(head_output)\n",
    "print(torch.eq(ori_out, head_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ori_body(input, B):\n",
    "    w = input.size(2) - 2*padding\n",
    "    Oc = input.permute(0, 1, 3, 4, 2)\n",
    "    # Add a new axis to B for broadcasting, B's shape becomes (1, 1, Cout, r, 1, d)\n",
    "    B_expanded = B[None, None, :, :, None, :]\n",
    "    # Assuming 'Oc' is a 5-dimensional and 'w' and 'd' are the window width and depth, respectively\n",
    "    window_indices = torch.arange(start=0, end=w, step=stride)[:, None] + torch.arange(kernel_size)\n",
    "    print(window_indices.shape)\n",
    "    Oc_expanded = Oc[:, :, :, :, window_indices]\n",
    "    print(Oc_expanded.shape)\n",
    "    print(B_expanded.shape)\n",
    "    print((Oc_expanded*B_expanded).shape)\n",
    "\n",
    "    # Perform the element-wise multiplication and sum over the last axis (d)\n",
    "    output = torch.sum(Oc_expanded * B_expanded, dim=-1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([1, 6, 3, 2, 4, 3])\n",
      "torch.Size([1, 1, 3, 2, 1, 3])\n",
      "torch.Size([1, 6, 3, 2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "B = torch.rand(out_channels, rank, kernel_size)\n",
    "ori_out_body = ori_body(ori_out, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0651, 0.1046, 0.1396, 0.0542],\n",
      "           [0.2413, 0.4901, 0.4289, 0.3241]],\n",
      "\n",
      "          [[0.0896, 0.2515, 0.3070, 0.3822],\n",
      "           [0.3641, 0.4279, 0.4391, 0.2073]],\n",
      "\n",
      "          [[0.3476, 0.6081, 0.7558, 0.6180],\n",
      "           [0.0240, 0.0447, 0.0519, 0.0195]]],\n",
      "\n",
      "\n",
      "         [[[0.0879, 0.0978, 0.1347, 0.0524],\n",
      "           [0.2957, 0.4828, 0.3676, 0.2078]],\n",
      "\n",
      "          [[0.0304, 0.1927, 0.3992, 0.3493],\n",
      "           [0.4205, 0.4331, 0.3009, 0.1131]],\n",
      "\n",
      "          [[0.3021, 0.5916, 0.8061, 0.5391],\n",
      "           [0.0360, 0.0364, 0.0493, 0.0191]]],\n",
      "\n",
      "\n",
      "         [[[0.1103, 0.1171, 0.1494, 0.0584],\n",
      "           [0.2832, 0.3277, 0.4479, 0.1536]],\n",
      "\n",
      "          [[0.0357, 0.2318, 0.4672, 0.3785],\n",
      "           [0.3935, 0.3795, 0.3179, 0.2167]],\n",
      "\n",
      "          [[0.3639, 0.6812, 0.9193, 0.5879],\n",
      "           [0.0436, 0.0360, 0.0591, 0.0191]]],\n",
      "\n",
      "\n",
      "         [[[0.1353, 0.0935, 0.1494, 0.0322],\n",
      "           [0.0905, 0.2024, 0.3507, 0.2491]],\n",
      "\n",
      "          [[0.1504, 0.4246, 0.3734, 0.2448],\n",
      "           [0.2209, 0.2486, 0.3845, 0.2785]],\n",
      "\n",
      "          [[0.5991, 0.7646, 0.7563, 0.4486],\n",
      "           [0.0398, 0.0323, 0.0622, 0.0083]]],\n",
      "\n",
      "\n",
      "         [[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000, 0.0000]]]]])\n",
      "torch.Size([1, 6, 3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(ori_out_body)\n",
    "print(ori_out_body.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_body(input, C, B):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "    for i in range(out_channels):\n",
    "        conv_head = nn.Conv2d(in_channels, rank, 1, padding=0, bias=False)\n",
    "        conv_head.weight.data = C[:, i, :].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv_head(input)\n",
    "        conv_body = nn.Conv2d(rank, 1, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "        conv_body.weight.data = B[i].unsqueeze(0).unsqueeze(2)\n",
    "        out = conv_body(out)\n",
    "\n",
    "        output[:, i] = out\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_out_body = my_body(input, C, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.3064, 0.5947, 0.5686, 0.3784],\n",
      "          [0.3837, 0.5806, 0.5023, 0.2603],\n",
      "          [0.3935, 0.4448, 0.5973, 0.2120],\n",
      "          [0.2258, 0.2959, 0.5000, 0.2813]],\n",
      "\n",
      "         [[0.4537, 0.6795, 0.7461, 0.5895],\n",
      "          [0.4509, 0.6258, 0.7002, 0.4625],\n",
      "          [0.4292, 0.6113, 0.7851, 0.5952],\n",
      "          [0.3713, 0.6732, 0.7579, 0.5234]],\n",
      "\n",
      "         [[0.3716, 0.6528, 0.8077, 0.6375],\n",
      "          [0.3380, 0.6280, 0.8554, 0.5582],\n",
      "          [0.4075, 0.7172, 0.9785, 0.6070],\n",
      "          [0.6389, 0.7969, 0.8185, 0.4569]]]], grad_fn=<CopySlices>)\n",
      "torch.Size([1, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(my_out_body)\n",
    "print(my_out_body.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_body_d(input, C, B):\n",
    "    conv = nn.Conv2d(in_channels, out_channels*rank, 1, padding=padding, bias=False)\n",
    "    conv.weight.data = C.reshape(in_channels, out_channels*rank).permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "    out = conv(input)\n",
    "\n",
    "    out = out.unsqueeze(1)\n",
    "    conv_body = nn.Conv3d(1, out_channels*rank, kernel_size, 1, padding=1, bias=False)\n",
    "    conv_body.weight.data = B.reshape(out_channels*rank, kernel_size).permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "    out = conv_body(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.5765, 0.6112, 0.8158, 0.8656, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3346, 0.8899, 0.7524, 0.5976, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2700, 1.0619, 0.6690, 0.7970, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.6699, 0.8508, 0.3570, 0.9570, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.5612, 0.5825, 0.7806, 0.7895, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3692, 0.8357, 0.6996, 0.5285, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2870, 0.9901, 0.5865, 0.7452, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.5870, 0.7443, 0.3489, 0.9046, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.5636, 0.5705, 0.7680, 0.7306, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.4216, 0.8034, 0.6641, 0.4684, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3165, 0.9432, 0.5132, 0.7125, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.5133, 0.6490, 0.3519, 0.8766, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_body_d(input, C, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ori_tail(input, A):\n",
    "    h = input.size(1) - 2*padding\n",
    "    Ob = input.permute(0, 4, 2, 3, 1)\n",
    "    # Add a new axis to B for broadcasting, A's shape becomes (1, 1, Cout, r, 1, d)\n",
    "    A_expanded = A[None, None, :, :, None, :]\n",
    "\n",
    "    # Assuming 'Ob' is a 5-dimensional and 'h' and 'd' are the window width and depth, respectively\n",
    "    window_indices = torch.arange(start=0, end=h, step=stride)[:, None] + torch.arange(kernel_size)\n",
    "    Ob_expanded = Ob[:, :, :, :, window_indices]\n",
    "\n",
    "    # Perform the element-wise multiplication and sum over the last axis (d)\n",
    "    Oa = torch.sum(Ob_expanded * A_expanded, axis=-1)\n",
    "\n",
    "    Oa = Oa.permute(0, 4, 1, 2, 3)\n",
    "\n",
    "    # print(Oa)\n",
    "\n",
    "    # Step 4: Compute O\n",
    "    output = torch.sum(Oa, dim=-1)\n",
    "\n",
    "    # print(output)\n",
    "\n",
    "    output = output.permute(0, 3, 1, 2)\n",
    "    # print(output)\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(out_channels, rank, kernel_size)\n",
    "ori_out_tail = ori_tail(ori_out_body, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2911, 0.5189, 0.4864, 0.3189],\n",
       "          [0.3858, 0.5787, 0.5232, 0.2741],\n",
       "          [0.3797, 0.4290, 0.5659, 0.2108],\n",
       "          [0.1319, 0.2191, 0.3594, 0.2203]],\n",
       "\n",
       "         [[0.2898, 0.4234, 0.5110, 0.3431],\n",
       "          [0.5886, 0.8285, 0.9320, 0.6531],\n",
       "          [0.6056, 0.8541, 0.8650, 0.5699],\n",
       "          [0.3927, 0.5159, 0.6416, 0.4719]],\n",
       "\n",
       "         [[0.1915, 0.3474, 0.4677, 0.3028],\n",
       "          [0.2426, 0.4124, 0.5611, 0.3444],\n",
       "          [0.3586, 0.4514, 0.4929, 0.2691],\n",
       "          [0.0525, 0.0645, 0.0837, 0.0399]]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_out_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tail(input, C, B, A):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "\n",
    "    for i in range(out_channels):\n",
    "\n",
    "        conv_head = nn.Conv2d(in_channels, rank, 1, padding=0, bias=False)\n",
    "        conv_head.weight.data = C[:, i, :].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv_head(input)\n",
    "        conv_body = nn.Conv2d(rank, 1, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "        conv_body.weight.data = B[i].unsqueeze(0).unsqueeze(2)\n",
    "        out = conv_body(out)\n",
    "\n",
    "        conv_tail = nn.Conv2d(1, rank, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "        conv_tail.weight.data = A[i].unsqueeze(1).unsqueeze(-1)\n",
    "        out = conv_tail(out)\n",
    "\n",
    "        # print(out.shape)\n",
    "        # print(out)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        # print(out.shape)\n",
    "        # print(out)\n",
    "\n",
    "\n",
    "        output[:, i] = out\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5819, 1.0000, 0.9144, 0.5501],\n",
       "          [0.7100, 0.9770, 1.0217, 0.4662],\n",
       "          [0.5993, 0.7335, 1.0207, 0.4576],\n",
       "          [0.2700, 0.3422, 0.5531, 0.2910]],\n",
       "\n",
       "         [[0.5954, 0.8540, 0.9476, 0.6796],\n",
       "          [1.0901, 1.5810, 1.8300, 1.3763],\n",
       "          [1.0307, 1.5595, 1.8045, 1.2518],\n",
       "          [0.6913, 1.0648, 1.3082, 0.9633]],\n",
       "\n",
       "         [[0.5250, 0.9631, 1.2850, 0.8748],\n",
       "          [0.6709, 1.1914, 1.6084, 1.0341],\n",
       "          [0.9628, 1.3107, 1.4677, 0.8554],\n",
       "          [0.2912, 0.4048, 0.4640, 0.2711]]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tail(input, C, B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_other(input, C, B, A):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "    for i in range(out_channels):\n",
    "\n",
    "        conv_head = nn.Conv2d(in_channels, rank, 1, padding=0, bias=False)\n",
    "        conv_head.weight.data = C[:, i, :].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv_head(input)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        output[:, i] = out\n",
    "\n",
    "    conv_body = nn.Conv2d(out_channels, rank, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "    conv_body.weight.data = B.permute(1, 0, 2).unsqueeze(2)\n",
    "    output = conv_body(output)\n",
    "\n",
    "    conv_tail = nn.Conv2d(rank, out_channels, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "    conv_tail.weight.data = A.unsqueeze(-1)\n",
    "    output = conv_tail(output)\n",
    "\n",
    "    # print(out.shape)\n",
    "    # print(out)\n",
    "    # out = torch.sum(out, dim=1)\n",
    "    # print(out.shape)\n",
    "    # print(out)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.2111, 3.5042, 3.6479, 2.2126],\n",
       "          [2.6232, 3.4829, 4.1524, 2.1182],\n",
       "          [2.4911, 3.3037, 4.0373, 2.0771],\n",
       "          [1.2614, 1.3922, 1.9186, 0.9906]],\n",
       "\n",
       "         [[1.7439, 2.7175, 2.7961, 1.6800],\n",
       "          [3.2875, 4.8101, 5.4602, 3.1393],\n",
       "          [3.2956, 4.5396, 5.1281, 2.7538],\n",
       "          [2.2895, 2.6967, 3.6302, 1.8064]],\n",
       "\n",
       "         [[2.0020, 2.9269, 2.9264, 1.6439],\n",
       "          [2.3810, 2.9948, 3.6546, 1.8197],\n",
       "          [2.1374, 2.6827, 3.4025, 1.7800],\n",
       "          [0.6455, 0.7104, 0.9502, 0.4761]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_other(input, C, B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_another(input, C, B, A):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "\n",
    "    for i in range(out_channels):\n",
    "        sum = torch.zeros(batch_size, 1, height, width)\n",
    "        for j in range(rank):\n",
    "\n",
    "            conv_head = nn.Conv2d(in_channels, 1, 1, padding=0, bias=False)\n",
    "            conv_head.weight.data = C[:, i, j].unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "            out = conv_head(input)\n",
    "\n",
    "            conv_body = nn.Conv2d(1, 1, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "            conv_body.weight.data = B[i, j].unsqueeze(0).unsqueeze(0).unsqueeze(0)\n",
    "            out = conv_body(out)\n",
    "\n",
    "            conv_tail = nn.Conv2d(1, 1, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "            conv_tail.weight.data = A[i, j].unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "            out = conv_tail(out)                      \n",
    "\n",
    "            sum += out\n",
    "\n",
    "        output[:, i] = sum\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2911, 0.5189, 0.4864, 0.3189],\n",
       "          [0.3858, 0.5787, 0.5232, 0.2741],\n",
       "          [0.3797, 0.4290, 0.5659, 0.2108],\n",
       "          [0.1319, 0.2191, 0.3594, 0.2203]],\n",
       "\n",
       "         [[0.2898, 0.4234, 0.5110, 0.3431],\n",
       "          [0.5886, 0.8285, 0.9320, 0.6531],\n",
       "          [0.6056, 0.8541, 0.8650, 0.5699],\n",
       "          [0.3927, 0.5159, 0.6416, 0.4719]],\n",
       "\n",
       "         [[0.1915, 0.3474, 0.4677, 0.3028],\n",
       "          [0.2426, 0.4124, 0.5611, 0.3444],\n",
       "          [0.3586, 0.4514, 0.4929, 0.2691],\n",
       "          [0.0525, 0.0645, 0.0837, 0.0399]]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_another(input, C, B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reshape(input, C, B, A):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "\n",
    "    conv_head = nn.Conv2d(in_channels, out_channels*rank, 1, padding=0, bias=False)\n",
    "    conv_head.weight.data = C.reshape(in_channels, out_channels*rank).permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "    out = conv_head(input)\n",
    "\n",
    "    conv_body = nn.Conv2d(out_channels*rank, 1, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "    conv_body.weight.data = B.reshape(out_channels*rank, kernel_size).unsqueeze(0).unsqueeze(2)\n",
    "    out = conv_body(out)\n",
    "\n",
    "    conv_tail = nn.Conv2d(1, out_channels*rank, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "    conv_tail.weight.data = A.reshape(out_channels*rank, kernel_size).unsqueeze(1).unsqueeze(-1)\n",
    "    out = conv_tail(out)\n",
    "\n",
    "    # conv_body = nn.Conv2d(out_channels*rank, 1, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "    # conv_body.weight.data = B.reshape(out_channels*rank, kernel_size).unsqueeze(0).unsqueeze(-1)\n",
    "    # out = conv_body(out)\n",
    "\n",
    "    # conv_tail = nn.Conv2d(1, out_channels*rank, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "    # conv_tail.weight.data = A.reshape(out_channels*rank, kernel_size).unsqueeze(1).unsqueeze(2)\n",
    "    # out = conv_tail(out)\n",
    "\n",
    "    x = out.reshape(batch_size, out_channels, rank, height, width)\n",
    "\n",
    "\n",
    "    output = torch.sum(x, dim=2)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.9564, 3.2032, 3.5576, 2.4735],\n",
       "          [2.2237, 3.3849, 4.0840, 2.5448],\n",
       "          [2.2874, 3.3084, 4.1252, 2.4930],\n",
       "          [1.3271, 1.8986, 2.2773, 1.3804]],\n",
       "\n",
       "         [[1.5216, 2.4673, 2.7460, 1.8671],\n",
       "          [2.8671, 4.5471, 5.3395, 3.6027],\n",
       "          [2.9498, 4.4030, 5.2183, 3.1939],\n",
       "          [2.0768, 2.9850, 3.8214, 2.2990]],\n",
       "\n",
       "         [[1.7696, 2.8197, 3.1503, 2.0543],\n",
       "          [2.0773, 3.1007, 3.9135, 2.4267],\n",
       "          [2.1113, 3.0535, 3.6611, 2.2239],\n",
       "          [0.6514, 0.9338, 1.1529, 0.6965]]]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reshape(input, C, B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func1(input, C, B, A):\n",
    "    output = torch.zeros(batch_size, out_channels, height, width)\n",
    "\n",
    "    for j in range(rank):\n",
    "\n",
    "        conv_head = nn.Conv2d(in_channels, out_channels, 1, padding=0, bias=False)\n",
    "        conv_head.weight.data = C[:, :, j].permute(1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = conv_head(input)\n",
    "\n",
    "        conv_body = nn.Conv2d(out_channels, 1, kernel_size=(1, kernel_size), padding=(0, padding), bias=False)\n",
    "        conv_body.weight.data = B[:, j].unsqueeze(0).unsqueeze(2)\n",
    "        out = conv_body(out)\n",
    "\n",
    "        conv_tail = nn.Conv2d(1, out_channels, kernel_size=(kernel_size, 1), padding=(padding, 0), bias=False)\n",
    "        conv_tail.weight.data = A[:, j].unsqueeze(1).unsqueeze(-1)\n",
    "        out = conv_tail(out)\n",
    "\n",
    "        output += out\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9362, 1.1645, 1.3074, 0.6042],\n",
       "          [1.4696, 1.8392, 2.0636, 1.0655],\n",
       "          [1.5086, 1.5645, 1.9697, 0.9215],\n",
       "          [0.7116, 0.8367, 0.9452, 0.5844]],\n",
       "\n",
       "         [[1.0254, 1.4558, 1.4889, 0.8978],\n",
       "          [1.2941, 1.8541, 1.7673, 0.9926],\n",
       "          [1.1364, 1.4900, 1.6468, 1.2225],\n",
       "          [0.8168, 0.8580, 1.2344, 0.8054]],\n",
       "\n",
       "         [[1.2643, 1.7145, 1.7769, 0.7809],\n",
       "          [1.9359, 2.5930, 2.7964, 1.5856],\n",
       "          [1.9326, 2.1265, 2.7178, 1.5271],\n",
       "          [1.3022, 1.3232, 1.6107, 0.6862]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func1(input, C, A, B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
