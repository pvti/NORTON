{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import argparse\n",
    "import copy\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data.distributed\n",
    "import torch.utils.data\n",
    "\n",
    "import utils.common as utils\n",
    "from data import cifar10\n",
    "from models.cifar10.vgg import vgg_16_bn\n",
    "from models.cifar10.resnet import resnet_56\n",
    "from decomposition.decomposition import decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = cifar10.load_data('../data', 256)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "\n",
    "# load model\n",
    "compress_rate = utils.get_cpr('[0.]*100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval('vgg_16_bn')(compress_rate=compress_rate).cuda()\n",
    "ckpt = torch.load('checkpoint/cifar10/vgg_16_bn.pt', map_location='cuda:0')\n",
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcp_model = decompose(model, 1, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn(1, 3, 32, 32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features.conv0(dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcp_model.features.conv0(dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    losses = utils.AverageMeter('Loss', ':.4e')\n",
    "    top1 = utils.AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = utils.AverageMeter('Acc@5', ':6.2f')\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            pred1, pred5 = utils.accuracy(logits, target, topk=(1, 5))\n",
    "            n = images.size(0)\n",
    "            losses.update(loss.item(), n)\n",
    "            top1.update(pred1[0], n)\n",
    "            top5.update(pred5[0], n)\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "                    .format(top1=top1, top5=top5))\n",
    "\n",
    "    return losses.avg, top1.avg, top5.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(val_loader, model, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
